{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "UBIT = 'mgosi'\n",
    "np.random.seed(sum([ord(c) for c in UBIT]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating SIFT Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = cv2.imread('mountain1.jpg')\n",
    "img2 = cv2.imread('mountain2.jpg')\n",
    "\n",
    "#Converting to Grayscale\n",
    "gray_1= cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "gray_2= cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Initializing Sift\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "#Applying Sift Algorithm to find the keypoints and their descriptors\n",
    "kp_1, desc_1 = sift.detectAndCompute(gray_1,None)\n",
    "kp_2, desc_2 = sift.detectAndCompute(gray_2,None)\n",
    "\n",
    "#Drawing corresponding Keypoints\n",
    "img_1=cv2.drawKeypoints(gray_1,kp_1,img_1)\n",
    "img_2=cv2.drawKeypoints(gray_2,kp_2,img_2)\n",
    "\n",
    "cv2.imwrite('task1_sift1.jpg',img_1)\n",
    "cv2.imwrite('task1_sift2.jpg',img_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching and Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.58720376e+00 -2.91747553e-01 -3.95226519e+02]\n",
      " [ 4.48097764e-01  1.43063310e+00 -1.90273584e+02]\n",
      " [ 1.20808480e-03 -6.07787702e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Using Brute Force matcher\n",
    "\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "#It tries to find the closest descriptor in the second set , and applyes KNN Matching to the descriptors\n",
    "matches = bf.knnMatch(desc_1, desc_2, k= 2)\n",
    "\n",
    "# store all the good_matches matches as per Lowe's ratio test.\n",
    "good_matches = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:      #Good matching criteria\n",
    "        good_matches.append(m)\n",
    "\n",
    "\n",
    "src_pts = np.float32([ kp_1[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)             #Gives us the index of the descriptor in the list of train descriptors \n",
    "dst_pts = np.float32([ kp_2[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)               #Gives us the index of the descriptor in the list of query descriptors \n",
    "\n",
    "#homography relates the transformation between two plane by using RANSAC Algorithm\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "matchesMask = mask.ravel().tolist()\n",
    "print (H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knn Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_pts1 = []\n",
    "ran_pts2 = []\n",
    "for i in [np.random.randint(0,len(good_matches) -1 ) for x in range(10)] :\n",
    "    ran_pts1.append(good_matches[i])\n",
    "    ran_pts2.append(matchesMask[i])\n",
    "\n",
    "#Plotting all the matches\n",
    "img_3 = cv2.drawMatches(img_1,kp_1,img_2,kp_2,good_matches,None,flags=2)\n",
    "cv2.imwrite(\"task1_matches_knn.jpg\",img_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching 10 Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters to draw the 10 random points and only inliners\n",
    "params = dict(matchColor = np.random.randint(low = 0, high = 255, size = 3).tolist(),\n",
    "                   matchesMask = ran_pts2, # draw only inliners\n",
    "                   flags = 2)\n",
    "\n",
    "#Plotting keypoints for only 10 Inliers\n",
    "img_4 = cv2.drawMatches(img_1,kp_1,img_2,kp_2,ran_pts1,None,**params)\n",
    "cv2.imwrite(\"task1_matches.jpg\",img_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height,width = img_1.shape[:2]\n",
    "pts = np.float32([ [0,0],[0,height-1],[width-1,height-1],[width-1,0] ]).reshape(-1,1,2)\n",
    "#Taking the border points of the image(i.e Corner Points)\n",
    "dst = cv2.perspectiveTransform(pts,H)\n",
    "\n",
    "#Extracting the rows and cols\n",
    "rows1, cols1 = img_1.shape[:2]\n",
    "rows2, cols2 = img_2.shape[:2]\n",
    "\n",
    "#Getting Border Points\n",
    "pts1 = np.float32([[0,0], [0,rows1], [cols1, rows1], [cols1,0]]).reshape(-1,1,2)\n",
    "temp_points = np.float32([[0,0], [0,rows2], [cols2, rows2], [cols2,0]]).reshape(-1,1,2)\n",
    "\n",
    "#Taking Perspective\n",
    "pts2 = cv2.perspectiveTransform(temp_points, H)\n",
    "pts = np.concatenate((pts1, pts2), axis=0)\n",
    "\n",
    "#For calculating the size of the output image\n",
    "[x_min, y_min] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "[x_max, y_max] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "\n",
    "trans_dist = [-x_min, -y_min]\n",
    "\n",
    "H_trans = np.array([[1, 0, trans_dist[0]], [0, 1, trans_dist[1]], [0,0,1]])\n",
    "#Warping image 1 on top of Image 2\n",
    "warp_img = cv2.warpPerspective(img1, H_trans.dot(H), (x_max - x_min, y_max - y_min))\n",
    "warp_img[trans_dist[1]:rows1+trans_dist[1],trans_dist[0]:cols1+trans_dist[0]] = img2\n",
    "\n",
    "cv2.imwrite(\"task1_pano.jpg\",warp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
